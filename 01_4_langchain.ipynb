{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_01_4_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euOZxlIMhstX"
   },
   "source": [
    "# T81-559: Applications of Generative Artificial Intelligence\n",
    "**Module 1: Course Overview**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Yov72PhstY"
   },
   "source": [
    "# Module 1 Material\n",
    "\n",
    "* Part 1.1: Course Overview [[Video]](https://www.youtube.com/watch?v=OVS-6s20Ms0) [[Notebook]](t81_559_class_01_1_overview.ipynb)\n",
    "* Part 1.2: Generative AI Overview [[Video]](https://www.youtube.com/watch?v=ohmPaSsKhMs) [[Notebook]](t81_559_class_01_2_genai.ipynb)\n",
    "* Part 1.3: Introduction to OpenAI [[Video]](https://www.youtube.com/watch?v=C2xyi2Cq-bU) [[Notebook]](t81_559_class_01_3_openai.ipynb)\n",
    "* **Part 1.4: Introduction to LangChain** [[Video]](https://www.youtube.com/watch?v=qQI5AhaKxuI) [[Notebook]](t81_559_class_01_4_langchain.ipynb)\n",
    "* Part 1.5: Prompt Engineering [[Video]](https://www.youtube.com/watch?v=_Uot1i5sIXo) [[Notebook]](t81_559_class_01_5_prompt_engineering.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcAUP0c3hstY"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running and maps Google Drive if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsI496h5hstZ",
    "outputId": "5f629e95-5dc9-4fc9-b4cd-17cce6e1e656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# OpenAI Secrets\n",
    "if COLAB:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Install needed libraries in CoLab\n",
    "if COLAB:\n",
    "    !pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "# Part 1.4: Introduction to LangChain\n",
    "\n",
    "One of the most intriguing and promising developments in the evolving landscape of language models and artificial intelligence is LangChain. This technology represents a significant leap forward in how we interact with and harness the capabilities of large language models (LLMs). As we delve into the intricacies of LangChain in this chapter, it's important to understand not just the technical underpinnings but also the user experience that makes it so revolutionary.\n",
    "\n",
    "## LangChain Chat Conversation Format\n",
    "\n",
    "To explore LangChain comprehensively, we will adopt a format that has become increasingly familiar and effective in LLMs: the chat conversation interface. This interactive style, reminiscent of how many of us communicate daily, offers a unique and accessible means to illustrate LangChain's capabilities, potential applications, and the nuances of its operation.\n",
    "\n",
    "We begin by importing the components from the LangChain library to support a chat-style interface to OpenAI. We will use the ChatOpenAI interface for the OpenAI family of LLM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K2lC_JK3guaj"
   },
   "outputs": [],
   "source": [
    "# Conversation Style Inteface\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmWHTAub0sTm"
   },
   "source": [
    "The conversation format consists of arrays of chat entries of the following three types:\n",
    "\n",
    "* **SystemMessage** - This class designates the system prompt that provides instructions to the AI on the nature of the conversation and hints and guidelines. Generally, there will be only one system message at the beginning of the array.\n",
    "* **HumanMessage** - This class designates the chat messages from outside the LLM, typically the human user.\n",
    "* **AIMessage** - This class designates the chat messages from the LLM as responses to the HumanMessage messages.\n",
    "\n",
    "Here we see the chain to ask a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V_sJoVYAtE6b"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that concisely and accurately answers questions.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is the capital of France?\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To7rZtUO4B8t"
   },
   "source": [
    "We now submit these messages and retrieve the output from the model. We will use gpt-4o-mini, which is good enough for this query. Further, we use a zero temperature; we are simply looking for a factual answer, and creativity is not a goal or concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xfb875JhtI6J",
    "outputId": "f4e120de-7a83-4b82-e10c-d8c3f990322b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "The capital of France is Paris.\n",
      "-----------\n",
      "{'token_usage': {'completion_tokens': 7, 'prompt_tokens': 32, 'total_tokens': 39, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'gpt-4o-mini'\n",
    "\n",
    "# Initialize the OpenAI LLM with your API key\n",
    "llm = ChatOpenAI(\n",
    "  model=MODEL,\n",
    "  temperature= 0.0,\n",
    "  n= 1,\n",
    "  max_tokens= 256)\n",
    "\n",
    "print(\"Model response:\")\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)\n",
    "print(\"-----------\")\n",
    "print(output.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be6a0hXj4lHj"
   },
   "source": [
    "The model that LangChain returns to you returns additional metadata. This data shows the token usage, which might be useful for estimating the total cost expected from this query.\n",
    "\n",
    "We can continue to grow this conversation if we wish. To do so, we added the model's response and another human question. Here, we will ask the model if it was sure about its last response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vJuMVHZ1jJ8",
    "outputId": "d34c6945-9d2b-41c4-8e02-33b5056a72d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemMessage : You are a helpful assistant that concisely and accurately answers questions.\n",
      "HumanMessage : What is the capital of France?\n",
      "AIMessage : The capital of France is Paris.\n",
      "HumanMessage : Are you sure, I think it was renamed for some reason?\n"
     ]
    }
   ],
   "source": [
    "messages.append(output)\n",
    "messages.append(HumanMessage(content=\"Are you sure, I think it was renamed for some reason?\"))\n",
    "for message in messages:\n",
    "    print(f\"{type(message).__name__} : {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8Z7DZRH5TFr"
   },
   "source": [
    "We can submit the conversation array to the model and see its latest response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qFxkEmAz1w1",
    "outputId": "f1928a10-db7f-4abc-92af-23e24cd8ecb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "No, Paris has not been renamed. It remains the capital of France.\n"
     ]
    }
   ],
   "source": [
    "print(\"Model response:\")\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9nvX9oA3a0Z"
   },
   "source": [
    "## Asking a Single Question\n",
    "\n",
    "If you wish to ask the model a single question, not as part of a conversation chain, you can pass a string to the model for a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "34-95k0qg8ss",
    "outputId": "5d93f5a9-1ba6-4b52-d3ec-a4a8fa76451f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of the latest available data, the five largest cities in the USA by population are:\\n\\n1. **New York City, New York**\\n2. **Los Angeles, California**\\n3. **Chicago, Illinois**\\n4. **Houston, Texas**\\n5. **Phoenix, Arizona**\\n\\nPlease note that population figures can change over time, so it's always a good idea to check the most recent census data or estimates for the latest numbers.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# complete\n",
    "\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "MODEL = 'gpt-4o-mini'\n",
    "\n",
    "# Initialize the OpenAI LLM (Language Learning Model) with your API key\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "\n",
    "# Define the question\n",
    "question = \"What are the five largest cities in the USA by population?\"\n",
    "\n",
    "# Use Langchain to call the OpenAI API\n",
    "# The method and parameters might differ based on the Langchain version\n",
    "response = llm.invoke(question)\n",
    "\n",
    "# Print the response\n",
    "display(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o2EkUkN3hEX"
   },
   "source": [
    "## Prompt Templates\n",
    "\n",
    "LangChain allows you to create chains of operations typically performed as part of an LLM-enabled application. One of these operations is a prompt template, which allows you to insert text into a previously created prompt. In this example, we will create a prompt template that asks the model to create a random blog post title.\n",
    "\n",
    "```\n",
    "Return only the title of a blog post article title on the topic of {topic} in {language}\n",
    "```\n",
    "\n",
    "To accomplish this objective, we will use a **PromptTemplate** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-g3zOXBmulc",
    "outputId": "fb7a08ec-2f47-4526-9605-c0116289334f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yrobi\\AppData\\Local\\Temp\\ipykernel_17220\\330050241.py:13: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True)\n",
      "C:\\Users\\yrobi\\AppData\\Local\\Temp\\ipykernel_17220\\330050241.py:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = title_chain.run({'topic':topic,'language':language })\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mReturn only the title of a blog post article title on the topic of pets for data scientists in english\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\"Data-Driven Insights: How Pets Can Enhance Your Work-Life Balance as a Data Scientist\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "topic = \"pets for data scientists\"\n",
    "language = \"english\"\n",
    "\n",
    "# Initialize the OpenAI LLM (Language Learning Model) with your API key\n",
    "# Use higher temperature for greater creativity\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0.7)\n",
    "\n",
    "title_template = PromptTemplate( input_variables = ['topic', 'language'],\\\n",
    "  template = 'Return only the title of a blog post article title on the topic of {topic} in {language}' )\n",
    "title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True)\n",
    "response = title_chain.run({'topic':topic,'language':language })\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOpAcj-byBPg"
   },
   "source": [
    "## Create a Simple Sequential Chain\n",
    "\n",
    "We will now use LangChain to tie multiple LLM calls into a longer chain using the **SimpleSequentialChain** class. We will use two smaller chains to create a title and body text for a blog post. We begin by defining the two prompts we will use to construct this blog post. Also, note that we request that the LLM utilize [markdown](https://en.wikipedia.org/wiki/Markdown) to generate the actual blog post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ELS-9JD3Sao6"
   },
   "outputs": [],
   "source": [
    "# Create the two prompt templates\n",
    "title_template = PromptTemplate( input_variables = ['topic'], template = 'Give me a blog post title on {topic} in English' )\n",
    "article_template = PromptTemplate( input_variables = ['title'], template = 'Write a blog post for {title}, format in markdown.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3vy7jf3-_xl"
   },
   "source": [
    "We will create the first chain to generate the random title. Here, we allow the user to specify the topic. We use a higher temperature to increase the creativity of the title. We also use a simpler model to minimize cost for the relatively simple task of title selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_KV8UJUDyP8M"
   },
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o-mini'\n",
    "\n",
    "# Create a chain to generate a random\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0.7)\n",
    "title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO0ielMf_xRa"
   },
   "source": [
    "Next, we compose the actual blog post; we will use a lower temperature to decrease creativity and cause the LLM to stick to factual information and avoid hallucinations. We also use a more complex model to provide a better article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G7OCQCggyHlB"
   },
   "outputs": [],
   "source": [
    "MODEL2 = 'gpt-4'\n",
    "\n",
    "# Create the article chain\n",
    "llm2 = ChatOpenAI(model=MODEL2, temperature=0.1)\n",
    "article_chain = LLMChain(llm=llm2, prompt=article_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rftFvMyBa4-"
   },
   "source": [
    "Now, we combine these two chains into one. The input to the first chain will be the selected topic. The first chain will then output the title to the second chain, which will, in turn, output the actual article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2ibHBt4eyKZt"
   },
   "outputs": [],
   "source": [
    "# Create a complete chain to create a new blog post\n",
    "complete_chain=SimpleSequentialChain(chains=[title_chain, article_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_7P-n_DBvpD"
   },
   "source": [
    "We can now display the final article. In this case, we requested an article on \"photography,\" and displayed the final article's markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwro_kfKXvml",
    "outputId": "d0118b4d-9c33-4882-8d5a-0fe4eb42ad59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGive me a blog post title on photography in English\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Capturing Moments: The Art and Science of Photography for Beginners\"\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a blog post for \"Capturing Moments: The Art and Science of Photography for Beginners\", format in markdown.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m# Capturing Moments: The Art and Science of Photography for Beginners\n",
      "\n",
      "Photography is a beautiful blend of art and science, capturing moments and emotions in a frame. It's a medium that allows us to tell stories, document our lives, and express our creativity. If you're a beginner in photography, you might be overwhelmed by the technical aspects and the myriad of equipment available. But don't worry, this blog post will guide you through the basics of photography and help you take your first steps into this fascinating world.\n",
      "\n",
      "## Understanding the Science Behind Photography\n",
      "\n",
      "Before we delve into the art of photography, it's essential to understand the science behind it. The fundamental principle of photography is light. The camera, whether it's a DSLR, a mirrorless, or even a smartphone camera, captures light to create an image.\n",
      "\n",
      "### The Exposure Triangle\n",
      "\n",
      "The exposure triangle consists of three elements: aperture, shutter speed, and ISO. These three settings work together to control the amount of light that reaches the camera sensor and affects how bright or dark your photo is (the exposure).\n",
      "\n",
      "1. **Aperture**: This refers to the size of the opening in the lens through which light enters the camera. A larger aperture (represented by a smaller f-number like f/1.8) lets in more light and creates a shallow depth of field, blurring the background. A smaller aperture (a larger f-number like f/16) lets in less light and creates a larger depth of field, keeping more of the scene in focus.\n",
      "\n",
      "2. **Shutter Speed**: This is the length of time the camera's shutter is open. Faster shutter speeds (like 1/2000) freeze action but let in less light, while slower shutter speeds (like 1/30) let in more light but can cause blur if the camera or subject moves.\n",
      "\n",
      "3. **ISO**: This controls the camera sensor's sensitivity to light. A lower ISO (like 100) is less sensitive to light but produces clearer images, while a higher ISO (like 3200) is more sensitive to light but can result in more noise or grain in the image.\n",
      "\n",
      "Understanding and balancing these three elements is key to achieving correctly exposed photos.\n",
      "\n",
      "## The Art of Photography\n",
      "\n",
      "Now that we've covered the science, let's move on to the art of photography. This is where your creativity comes into play.\n",
      "\n",
      "### Composition\n",
      "\n",
      "Composition refers to how elements are arranged in a photo. Good composition can make a photo more interesting and engaging. Here are a few basic rules of composition:\n",
      "\n",
      "1. **Rule of Thirds**: Imagine dividing your frame into nine equal parts by two equally-spaced horizontal lines and two equally-spaced vertical lines. The rule of thirds suggests that you place your main subject along these lines or at their intersections for a more balanced photo.\n",
      "\n",
      "2. **Leading Lines**: These are lines that lead the viewer's eye towards the main subject. They can be anything from roads and fences to shadows and light streaks.\n",
      "\n",
      "3. **Framing**: This involves using natural frames like windows, arches, or branches to draw attention to your subject.\n",
      "\n",
      "Remember, these rules are not set in stone. They're more like guidelines, and sometimes breaking them can result in stunning photos.\n",
      "\n",
      "### Experiment and Practice\n",
      "\n",
      "The best way to improve your photography skills is by practicing. Take your camera everywhere and shoot anything and everything. Experiment with different settings, compositions, and lighting conditions. Don't be afraid to make mistakes. Each mistake is a learning opportunity.\n",
      "\n",
      "Photography is a journey. It's about capturing moments, expressing your creativity, and telling stories. So, grab your camera and start exploring the world through your lens. Happy shooting!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display_markdown\n",
    "\n",
    "article = complete_chain.invoke('photography')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1pN8CbXCE6F"
   },
   "source": [
    "The actual display of the markdown is handled by this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "Vt5uGJawuru_",
    "outputId": "7ff949a4-294f-43fb-afb7-7785aa22b673"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Capturing Moments: The Art and Science of Photography for Beginners\n",
       "\n",
       "Photography is a beautiful blend of art and science, capturing moments and emotions in a frame. It's a medium that allows us to tell stories, document our lives, and express our creativity. If you're a beginner in photography, you might be overwhelmed by the technical aspects and the myriad of equipment available. But don't worry, this blog post will guide you through the basics of photography and help you take your first steps into this fascinating world.\n",
       "\n",
       "## Understanding the Science Behind Photography\n",
       "\n",
       "Before we delve into the art of photography, it's essential to understand the science behind it. The fundamental principle of photography is light. The camera, whether it's a DSLR, a mirrorless, or even a smartphone camera, captures light to create an image.\n",
       "\n",
       "### The Exposure Triangle\n",
       "\n",
       "The exposure triangle consists of three elements: aperture, shutter speed, and ISO. These three settings work together to control the amount of light that reaches the camera sensor and affects how bright or dark your photo is (the exposure).\n",
       "\n",
       "1. **Aperture**: This refers to the size of the opening in the lens through which light enters the camera. A larger aperture (represented by a smaller f-number like f/1.8) lets in more light and creates a shallow depth of field, blurring the background. A smaller aperture (a larger f-number like f/16) lets in less light and creates a larger depth of field, keeping more of the scene in focus.\n",
       "\n",
       "2. **Shutter Speed**: This is the length of time the camera's shutter is open. Faster shutter speeds (like 1/2000) freeze action but let in less light, while slower shutter speeds (like 1/30) let in more light but can cause blur if the camera or subject moves.\n",
       "\n",
       "3. **ISO**: This controls the camera sensor's sensitivity to light. A lower ISO (like 100) is less sensitive to light but produces clearer images, while a higher ISO (like 3200) is more sensitive to light but can result in more noise or grain in the image.\n",
       "\n",
       "Understanding and balancing these three elements is key to achieving correctly exposed photos.\n",
       "\n",
       "## The Art of Photography\n",
       "\n",
       "Now that we've covered the science, let's move on to the art of photography. This is where your creativity comes into play.\n",
       "\n",
       "### Composition\n",
       "\n",
       "Composition refers to how elements are arranged in a photo. Good composition can make a photo more interesting and engaging. Here are a few basic rules of composition:\n",
       "\n",
       "1. **Rule of Thirds**: Imagine dividing your frame into nine equal parts by two equally-spaced horizontal lines and two equally-spaced vertical lines. The rule of thirds suggests that you place your main subject along these lines or at their intersections for a more balanced photo.\n",
       "\n",
       "2. **Leading Lines**: These are lines that lead the viewer's eye towards the main subject. They can be anything from roads and fences to shadows and light streaks.\n",
       "\n",
       "3. **Framing**: This involves using natural frames like windows, arches, or branches to draw attention to your subject.\n",
       "\n",
       "Remember, these rules are not set in stone. They're more like guidelines, and sometimes breaking them can result in stunning photos.\n",
       "\n",
       "### Experiment and Practice\n",
       "\n",
       "The best way to improve your photography skills is by practicing. Take your camera everywhere and shoot anything and everything. Experiment with different settings, compositions, and lighting conditions. Don't be afraid to make mistakes. Each mistake is a learning opportunity.\n",
       "\n",
       "Photography is a journey. It's about capturing moments, expressing your creativity, and telling stories. So, grab your camera and start exploring the world through your lens. Happy shooting!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_key = complete_chain.output_key\n",
    "\n",
    "display_markdown(article[output_key], raw=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
